{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02845914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vikas\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45d496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe19702",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tracks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tracks = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtracks.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[32m      2\u001b[39m features = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33mfeatures.csv\u001b[39m\u001b[33m\"\u001b[39m, index_col = \u001b[32m0\u001b[39m) \n\u001b[32m      4\u001b[39m tracks_filtered = tracks[tracks[(\u001b[33m\"\u001b[39m\u001b[33mset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msubset\u001b[39m\u001b[33m\"\u001b[39m)] == \u001b[33m\"\u001b[39m\u001b[33msmall\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'tracks.csv'"
     ]
    }
   ],
   "source": [
    "tracks = pd.read_csv(\"tracks.csv\" , index_col = 0, header = [0, 1])  \n",
    "features = pd.read_csv(\"features.csv\", index_col = 0) \n",
    "\n",
    "tracks_filtered = tracks[tracks[(\"set\", \"subset\")] == \"small\"]\n",
    "tracks_id = tracks_filtered.index\n",
    "genre = tracks_filtered[(\"track\", \"genre_top\")]\n",
    "features_filtered = features.reindex(tracks_id)\n",
    "\n",
    "genre_df = genre.reset_index(name = \"genre\")\n",
    "features_df = features_filtered.reset_index()\n",
    "\n",
    "print(features_df.head())\n",
    "\n",
    "features_df.drop(['track_id'], axis = 1)\n",
    "genre_df = genre_df[['genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391ac041",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_df, genre_df.values, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "y_train = y_train.flatten()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('svm', SVC(random_state=42))\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ba184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training the model\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"Making predictions\")\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb24f4",
   "metadata": {},
   "source": [
    "# Dataset Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4c5aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries for Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Visualization libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd3fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: tracks.csv not found. Please ensure the file is in the current directory.\n"
     ]
    }
   ],
   "source": [
    "# Load and Inspect Dataset\n",
    "try:\n",
    "    df_viz = pd.read_csv(\"tracks.csv\", header=[0, 1])  # dataset has hierarchical headers\n",
    "    print(f\"Dataset loaded successfully. Shape: {df_viz.shape}\")\n",
    "    print(f\"Columns: {df_viz.columns.tolist()[:10]}...\")  # Show first 10 columns\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: tracks.csv not found. Please ensure the file is in the current directory.\")\n",
    "    df_viz = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117356f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot proceed with data preprocessing as dataset was not loaded.\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing and Cleaning\n",
    "if df_viz is not None:\n",
    "    # Extract top-level genre (second row of headers has labels)\n",
    "    if (\"track\", \"genre_top\") in df_viz.columns:\n",
    "        genres = df_viz[(\"track\", \"genre_top\")]\n",
    "        print(\"Successfully found 'genre_top' column\")\n",
    "    else:\n",
    "        # Try alternative column names\n",
    "        possible_columns = [col for col in df_viz.columns if 'genre' in str(col).lower()]\n",
    "        print(f\"Available columns with 'genre': {possible_columns}\")\n",
    "        raise KeyError(\"Could not find 'genre_top' column in tracks.csv\")\n",
    "    \n",
    "    # Remove any missing values\n",
    "    genres = genres.dropna()\n",
    "    print(f\"Total tracks with genre information: {len(genres)}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Unique genres: {genres.nunique()}\")\n",
    "    print(f\"Missing values: {df_viz[('track', 'genre_top')].isnull().sum()}\")\n",
    "else:\n",
    "    print(\"Cannot proceed with data preprocessing as dataset was not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81ed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre Distribution Analysis\n",
    "if 'genres' in locals() and genres is not None:\n",
    "    # Count occurrences\n",
    "    genre_counts = genres.value_counts()\n",
    "    print(f\"Number of unique genres: {len(genre_counts)}\")\n",
    "    print(\"\\nGenre distribution:\")\n",
    "    print(genre_counts)\n",
    "    \n",
    "    # Display top 5 and bottom 5 genres\n",
    "    print(f\"\\nTop 5 most common genres:\")\n",
    "    for genre, count in genre_counts.head(5).items():\n",
    "        print(f\"  {genre}: {count:,} tracks ({count/len(genres)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nTop 5 least common genres:\")\n",
    "    for genre, count in genre_counts.tail(5).items():\n",
    "        print(f\"  {genre}: {count:,} tracks ({count/len(genres)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"Cannot proceed with analysis - genre data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Multiple Visualization Plots\n",
    "if 'genre_counts' in locals() and genre_counts is not None:\n",
    "    # Create multiple visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # 1. Bar plot\n",
    "    genre_counts.plot(kind=\"bar\", ax=axes[0,0], color='skyblue')\n",
    "    axes[0,0].set_title(\"Track Count per Genre (Bar Plot)\", fontsize=14, fontweight='bold')\n",
    "    axes[0,0].set_xlabel(\"Genre\")\n",
    "    axes[0,0].set_ylabel(\"Number of Tracks\")\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # 2. Pie chart (top 8 genres + others)\n",
    "    top_genres = genre_counts.head(8)\n",
    "    others_count = genre_counts.tail(len(genre_counts) - 8).sum()\n",
    "    if others_count > 0:\n",
    "        pie_data = pd.concat([top_genres, pd.Series([others_count], index=['Others'])])\n",
    "    else:\n",
    "        pie_data = top_genres\n",
    "\n",
    "    axes[0,1].pie(pie_data.values, labels=pie_data.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0,1].set_title(\"Genre Distribution (Pie Chart)\", fontsize=14, fontweight='bold')\n",
    "\n",
    "    # 3. Horizontal bar plot (sorted)\n",
    "    genre_counts.plot(kind=\"barh\", ax=axes[1,0], color='lightcoral')\n",
    "    axes[1,0].set_title(\"Track Count per Genre (Horizontal)\", fontsize=14, fontweight='bold')\n",
    "    axes[1,0].set_xlabel(\"Number of Tracks\")\n",
    "    axes[1,0].set_ylabel(\"Genre\")\n",
    "\n",
    "    # 4. Statistics summary\n",
    "    axes[1,1].axis('off')\n",
    "    stats_text = f\"\"\"\n",
    "Dataset Statistics:\n",
    "\n",
    "Total Tracks: {len(genres):,}\n",
    "Unique Genres: {len(genre_counts)}\n",
    "\n",
    "Top 5 Genres:\n",
    "{chr(10).join([f\"{genre}: {count:,} ({count/len(genres)*100:.1f}%)\" \n",
    "               for genre, count in genre_counts.head(5).items()])}\n",
    "\n",
    "Least Common Genre:\n",
    "{genre_counts.index[-1]}: {genre_counts.iloc[-1]:,} tracks\n",
    "\n",
    "Average tracks per genre: {genre_counts.mean():.0f}\n",
    "Median tracks per genre: {genre_counts.median():.0f}\n",
    "\"\"\"\n",
    "    axes[1,1].text(0.1, 0.9, stats_text, transform=axes[1,1].transAxes, \n",
    "                   fontsize=12, verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot create visualizations - genre count data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50fdbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Detailed Bar Chart with Labels\n",
    "if 'genre_counts' in locals() and genre_counts is not None:\n",
    "    # Additional detailed bar plot for better readability\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.bar(range(len(genre_counts)), genre_counts.values, color='steelblue', alpha=0.8)\n",
    "    plt.title(\"Detailed Track Count per Genre\", fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel(\"Genre\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Tracks\", fontsize=12)\n",
    "    plt.xticks(range(len(genre_counts)), genre_counts.index, rotation=45, ha='right')\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                 f'{int(height):,}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot create detailed chart - genre count data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8367a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Visualizations\n",
    "if 'genre_counts' in locals() and genre_counts is not None:\n",
    "    # Recreate and save the comprehensive plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Recreate all plots for saving\n",
    "    genre_counts.plot(kind=\"bar\", ax=axes[0,0], color='skyblue')\n",
    "    axes[0,0].set_title(\"Track Count per Genre (Bar Plot)\", fontsize=14, fontweight='bold')\n",
    "    axes[0,0].set_xlabel(\"Genre\")\n",
    "    axes[0,0].set_ylabel(\"Number of Tracks\")\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    top_genres = genre_counts.head(8)\n",
    "    others_count = genre_counts.tail(len(genre_counts) - 8).sum()\n",
    "    if others_count > 0:\n",
    "        pie_data = pd.concat([top_genres, pd.Series([others_count], index=['Others'])])\n",
    "    else:\n",
    "        pie_data = top_genres\n",
    "    \n",
    "    axes[0,1].pie(pie_data.values, labels=pie_data.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0,1].set_title(\"Genre Distribution (Pie Chart)\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "    genre_counts.plot(kind=\"barh\", ax=axes[1,0], color='lightcoral')\n",
    "    axes[1,0].set_title(\"Track Count per Genre (Horizontal)\", fontsize=14, fontweight='bold')\n",
    "    axes[1,0].set_xlabel(\"Number of Tracks\")\n",
    "    axes[1,0].set_ylabel(\"Genre\")\n",
    "    \n",
    "    axes[1,1].axis('off')\n",
    "    stats_text = f\"\"\"Dataset Statistics:\n",
    "\n",
    "Total Tracks: {len(genres):,}\n",
    "Unique Genres: {len(genre_counts)}\n",
    "\n",
    "Top 5 Genres:\n",
    "{chr(10).join([f\"{genre}: {count:,} ({count/len(genres)*100:.1f}%)\" \n",
    "               for genre, count in genre_counts.head(5).items()])}\n",
    "\n",
    "Least Common Genre:\n",
    "{genre_counts.index[-1]}: {genre_counts.iloc[-1]:,} tracks\n",
    "\n",
    "Average tracks per genre: {genre_counts.mean():.0f}\n",
    "Median tracks per genre: {genre_counts.median():.0f}\"\"\"\n",
    "    \n",
    "    axes[1,1].text(0.1, 0.9, stats_text, transform=axes[1,1].transAxes, \n",
    "                   fontsize=12, verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"genre_distribution_complete.png\", dpi=300, bbox_inches='tight')\n",
    "    print(\"Comprehensive visualization saved as 'genre_distribution_complete.png'\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save detailed bar chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    bars = plt.bar(range(len(genre_counts)), genre_counts.values, color='steelblue', alpha=0.8)\n",
    "    plt.title(\"Detailed Track Count per Genre\", fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel(\"Genre\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Tracks\", fontsize=12)\n",
    "    plt.xticks(range(len(genre_counts)), genre_counts.index, rotation=45, ha='right')\n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                 f'{int(height):,}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"genre_distribution_detailed.png\", dpi=300, bbox_inches='tight')\n",
    "    print(\"Detailed bar chart saved as 'genre_distribution_detailed.png'\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot save visualizations - genre count data not available.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
